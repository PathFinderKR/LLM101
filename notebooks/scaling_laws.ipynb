{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Scaling Laws",
   "id": "b175c885759ad86f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries",
   "id": "8545c1111c0df627"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-04T05:08:26.188581Z",
     "start_time": "2025-02-04T05:08:25.137443Z"
    }
   },
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from models.mlp.mlp import MLP, MLPConfig\n",
    "from models.gpt.gpt import GPT, GPTConfig\n",
    "from src.utils import load_text, set_seed, configure_device\n",
    "from src.tokenizer import CharTokenizer, BPETokenizer\n",
    "from src.train import split_text, TextDataset, setup_optimizer, setup_scheduler, train_epoch, evaluate"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "2b70b152bc4f266f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class CONFIG:\n",
    "    debug: bool = False\n",
    "    root_dir: str = os.getcwd() + \"/../\"\n",
    "    dataset_path: str = 'data/raw/shakespeare.txt'\n",
    "    device: torch.device = torch.device('cpu')  # Automatic device configuration\n",
    "\n",
    "    # wandb\n",
    "    project: str = \"LLM101-Scaling-Laws\"\n",
    "\n",
    "    # Tokenizer\n",
    "    tokenizer: str = \"char\"  # char or bpe\n",
    "\n",
    "    # Model\n",
    "    model: str = \"gpt\"  # gpt or mlp\n",
    "    if model == \"mlp\":\n",
    "        context_size: int = 16\n",
    "        d_embed: int = 256\n",
    "        d_ff: int = 1024\n",
    "    elif model == \"gpt\":\n",
    "        context_size: int = 4\n",
    "        n_layer: int = 2\n",
    "        n_head: int = 2\n",
    "        d_embed: int = 128\n",
    "        d_ff: int = 512\n",
    "        dropout: float = 0.2\n",
    "        flash_attention: bool = False\n",
    "    elif model == \"megabyte\":\n",
    "        pass\n",
    "\n",
    "    # Training\n",
    "    val_size: float = 0.05\n",
    "    epochs: int = 1\n",
    "    batch_size: int = 64\n",
    "    optimizer: str = \"AdamW\"  # AdamW or SGD\n",
    "    learning_rate: float = 0.001\n",
    "    weight_decay: float = 0.01\n",
    "    scheduler: str = \"cosine\"  # cosine or linear\n",
    "    warmup_ratio: float = 0.1\n",
    "    grad_clip: float = 1.0\n",
    "    mixed_precision: bool = False\n",
    "    seed: int = 101"
   ],
   "id": "de99377c65ef95e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Weights & Biases",
   "id": "7d9e2ffb9ad85fad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if not CONFIG.debug:\n",
    "    import wandb\n",
    "    wandb.login(key=os.environ.get(\"WANDB_API_KEY\"))\n",
    "    wandb_run = wandb.init(\n",
    "        project=CONFIG.project,\n",
    "        config=CONFIG.__dict__,\n",
    "        dir=CONFIG.root_dir\n",
    "    )\n",
    "    print(f\"Wandb run initialized: {wandb_run.id}\")\n",
    "else:\n",
    "    wandb_run = None\n",
    "    print(\"Debug mode enabled.\")"
   ],
   "id": "c7b10dfebaac1eea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reproducibility",
   "id": "2688c7ace8263583"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "set_seed(CONFIG.seed)",
   "id": "2324a82246b239ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "5c50204a9eb4ea16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "CONFIG.device = configure_device()",
   "id": "7dfbb4010f2cb4f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizer",
   "id": "91d6b049657b641a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize tokenizer\n",
    "if CONFIG.tokenizer == \"char\":\n",
    "    tokenizer = CharTokenizer()\n",
    "elif CONFIG.tokenizer == \"bpe\":\n",
    "    tokenizer = BPETokenizer()\n",
    "else:\n",
    "    raise ValueError(\"Invalid tokenizer type. Choose 'char' or 'bpe'.\")\n",
    "\n",
    "## Text to build vocabulary\n",
    "vocab_text = load_text(CONFIG.root_dir + CONFIG.dataset_path)\n",
    "\n",
    "## Build vocabulary\n",
    "tokenizer.build_vocab(vocab_text)"
   ],
   "id": "f5018125ef46b0f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "b3828acf86454a8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize model\n",
    "if CONFIG.model == \"mlp\":\n",
    "    model = MLP(MLPConfig(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        context_size=CONFIG.context_size,\n",
    "        d_embed=CONFIG.d_embed,\n",
    "        d_ff=CONFIG.d_ff\n",
    "    ))\n",
    "elif CONFIG.model == \"gpt\":\n",
    "    model = GPT(GPTConfig(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        context_size=CONFIG.context_size,\n",
    "        n_layer=CONFIG.n_layer,\n",
    "        n_head=CONFIG.n_head,\n",
    "        d_embed=CONFIG.d_embed,\n",
    "        d_ff=CONFIG.d_ff,\n",
    "        dropout=CONFIG.dropout\n",
    "    ))\n",
    "else:\n",
    "    raise ValueError(\"Invalid model type. Choose 'mlp' or 'gpt'.\")\n",
    "\n",
    "model.to(CONFIG.device)\n",
    "print(model)"
   ],
   "id": "9ca8932391ce184d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "3a3ec6dc84497a46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load text dataset to train the model\n",
    "text = load_text(CONFIG.root_dir + CONFIG.dataset_path)\n",
    "\n",
    "# Split text into training and validation sets\n",
    "train_text, val_text = split_text(text, CONFIG.val_size)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TextDataset(tokenizer, train_text, CONFIG.context_size)\n",
    "val_dataset = TextDataset(tokenizer, val_text, CONFIG.context_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG.batch_size, shuffle=False)"
   ],
   "id": "226b0d8f295df233"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "10c5878de8934f23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Setup optimizer and scheduler\n",
    "optimizer = setup_optimizer(model, CONFIG.optimizer, CONFIG.learning_rate, CONFIG.weight_decay)\n",
    "scheduler = setup_scheduler(optimizer, CONFIG.scheduler, CONFIG.warmup_ratio, len(train_loader) * CONFIG.epochs)\n",
    "\n",
    "# Train model\n",
    "for epoch in range(CONFIG.epochs):\n",
    "    train_epoch(model, train_loader, optimizer, scheduler, epoch, CONFIG.epochs, CONFIG.grad_clip, CONFIG.device, wandb_run)\n",
    "    evaluate(model, val_loader, epoch, wandb_run)\n",
    "\n",
    "# Finish wandb run\n",
    "if wandb_run is not None:\n",
    "    wandb_run.finish()"
   ],
   "id": "c5dff1ce049405f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
