{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Scaling Laws",
   "id": "b175c885759ad86f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries",
   "id": "8545c1111c0df627"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-02-05T05:56:21.255810Z",
     "start_time": "2025-02-05T05:56:20.646130Z"
    }
   },
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from models.mlp.mlp import MLP, MLPConfig\n",
    "from models.gpt.gpt import GPT, GPTConfig\n",
    "from src.utils import load_text, set_seed, configure_device\n",
    "from src.tokenizer import CharTokenizer, BPETokenizer\n",
    "from src.train import split_text, TextDataset, setup_optimizer, setup_scheduler, train_steps"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "2b70b152bc4f266f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class CONFIG:\n",
    "    debug: bool = False\n",
    "    root_dir: str = os.getcwd() + \"/../\"\n",
    "    dataset_path: str = 'data/raw/shakespeare.txt'\n",
    "    device: torch.device = torch.device('cpu')  # Automatic device configuration\n",
    "\n",
    "    # wandb\n",
    "    project: str = \"LLM101-Scaling-Laws\"\n",
    "\n",
    "    # Tokenizer\n",
    "    tokenizer: str = \"char\"  # char or bpe\n",
    "\n",
    "    # Model\n",
    "    model: str = \"gpt\"  # gpt or mlp\n",
    "    if model == \"mlp\":\n",
    "        context_size: int = 16\n",
    "        d_embed: int = 256\n",
    "        d_ff: int = 1024\n",
    "    elif model == \"gpt\":\n",
    "        context_size: int = 4\n",
    "        n_layer: int = 2\n",
    "        n_head: int = 2\n",
    "        d_embed: int = 128\n",
    "        d_ff: int = 512\n",
    "        dropout: float = 0.2\n",
    "        flash_attention: bool = False\n",
    "    elif model == \"megabyte\":\n",
    "        pass\n",
    "\n",
    "    # Training\n",
    "    val_size: float = 0.05\n",
    "    max_steps: int = 1000\n",
    "    val_interval: int = 500\n",
    "    batch_size: int = 64\n",
    "    optimizer: str = \"AdamW\"  # AdamW or SGD\n",
    "    learning_rate: float = 0.001\n",
    "    weight_decay: float = 0.01\n",
    "    scheduler: str = \"cosine\"  # cosine or linear\n",
    "    warmup_ratio: float = 0.1\n",
    "    grad_clip: float = 1.0\n",
    "    mixed_precision: bool = False\n",
    "    seed: int = 101"
   ],
   "id": "de99377c65ef95e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Weights & Biases",
   "id": "7d9e2ffb9ad85fad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not CONFIG.debug:\n",
    "    import wandb\n",
    "    wandb.login(key=os.environ.get(\"WANDB_API_KEY\"))\n",
    "    wandb_run = wandb.init(\n",
    "        project=CONFIG.project,\n",
    "        dir=CONFIG.root_dir\n",
    "    )\n",
    "    print(f\"Wandb run initialized: {wandb_run.id}\")\n",
    "else:\n",
    "    wandb_run = None\n",
    "    print(\"Debug mode enabled.\")"
   ],
   "id": "c7b10dfebaac1eea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reproducibility",
   "id": "2688c7ace8263583"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "set_seed(CONFIG.seed)",
   "id": "2324a82246b239ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "5c50204a9eb4ea16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "CONFIG.device = configure_device()",
   "id": "7dfbb4010f2cb4f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizer",
   "id": "91d6b049657b641a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize tokenizer\n",
    "if CONFIG.tokenizer == \"char\":\n",
    "    tokenizer = CharTokenizer()\n",
    "elif CONFIG.tokenizer == \"bpe\":\n",
    "    tokenizer = BPETokenizer()\n",
    "else:\n",
    "    raise ValueError(\"Invalid tokenizer type. Choose 'char' or 'bpe'.\")\n",
    "\n",
    "## Text to build vocabulary\n",
    "vocab_text = load_text(CONFIG.root_dir + CONFIG.dataset_path)\n",
    "\n",
    "## Build vocabulary\n",
    "tokenizer.build_vocab(vocab_text)"
   ],
   "id": "f5018125ef46b0f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "b3828acf86454a8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize model\n",
    "if CONFIG.model == \"mlp\":\n",
    "    model = MLP(MLPConfig(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        context_size=CONFIG.context_size,\n",
    "        d_embed=CONFIG.d_embed,\n",
    "        d_ff=CONFIG.d_ff\n",
    "    ))\n",
    "elif CONFIG.model == \"gpt\":\n",
    "    model = GPT(GPTConfig(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        context_size=CONFIG.context_size,\n",
    "        n_layer=CONFIG.n_layer,\n",
    "        n_head=CONFIG.n_head,\n",
    "        d_embed=CONFIG.d_embed,\n",
    "        d_ff=CONFIG.d_ff,\n",
    "        dropout=CONFIG.dropout\n",
    "    ))\n",
    "else:\n",
    "    raise ValueError(\"Invalid model type. Choose 'mlp' or 'gpt'.\")\n",
    "\n",
    "model.to(CONFIG.device)\n",
    "print(model)"
   ],
   "id": "9ca8932391ce184d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "3a3ec6dc84497a46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load text dataset to train the model\n",
    "text = load_text(CONFIG.root_dir + CONFIG.dataset_path)\n",
    "\n",
    "# Split text into training and validation sets\n",
    "train_text, val_text = split_text(text, CONFIG.val_size)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TextDataset(train_text, tokenizer, CONFIG.context_size)\n",
    "val_dataset = TextDataset(val_text, tokenizer, CONFIG.context_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG.batch_size, shuffle=False)"
   ],
   "id": "226b0d8f295df233",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "10c5878de8934f23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup optimizer and scheduler\n",
    "optimizer = setup_optimizer(model, CONFIG.optimizer, CONFIG.learning_rate, CONFIG.weight_decay)\n",
    "scheduler = setup_scheduler(optimizer, CONFIG.scheduler, CONFIG.warmup_ratio, len(train_loader) * CONFIG.max_steps)\n",
    "\n",
    "# Train model\n",
    "train_steps(model, train_loader, val_loader, optimizer, scheduler, CONFIG.max_steps, CONFIG.val_interval, CONFIG.grad_clip, CONFIG.device, wandb_run)\n",
    "\n",
    "# Finish wandb run\n",
    "if wandb_run is not None:\n",
    "    wandb_run.finish()"
   ],
   "id": "c5dff1ce049405f9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4118]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4119]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4118]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4117]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4120]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4117]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4118]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4117]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4115]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4116]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4115]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4116]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4116]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4115]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4114]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4113]\u001B[A\n",
      "Validation:  60%|█████▉    | 521/872 [00:04<00:02, 157.05it/s, loss=4.4112]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4112]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4112]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4110]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4110]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4109]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4109]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4107]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4107]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4105]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4106]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4105]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4106]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4105]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4106]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4106]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4108]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4108]\u001B[A\n",
      "Validation:  62%|██████▏   | 540/872 [00:04<00:02, 164.26it/s, loss=4.4108]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4108]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4107]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4107]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4108]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4108]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4109]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4109]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4108]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4106]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4107]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4107]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4106]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4107]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4104]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4105]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4105]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4106]\u001B[A\n",
      "Validation:  64%|██████▍   | 557/872 [00:04<00:01, 163.44it/s, loss=4.4106]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4106]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4105]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4104]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4104]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4106]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4104]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4103]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4103]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4103]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4103]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4103]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4103]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4102]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4102]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4101]\u001B[A\n",
      "Validation:  66%|██████▌   | 574/872 [00:04<00:02, 144.21it/s, loss=4.4100]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4100]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4099]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4100]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4099]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4098]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4100]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4099]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4100]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4101]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4100]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4099]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4098]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4097]\u001B[A\n",
      "Validation:  68%|██████▊   | 589/872 [00:04<00:02, 114.87it/s, loss=4.4096]\u001B[A\n",
      "Validation:  69%|██████▉   | 602/872 [00:04<00:02, 111.64it/s, loss=4.4096]\u001B[A\n",
      "Validation:  69%|██████▉   | 602/872 [00:04<00:02, 111.64it/s, loss=4.4096]\u001B[A\n",
      "Validation:  69%|██████▉   | 602/872 [00:04<00:02, 111.64it/s, loss=4.4095]\u001B[A\n",
      "Validation:  69%|██████▉   | 602/872 [00:04<00:02, 111.64it/s, loss=4.4094]\u001B[A\n",
      "Validation:  69%|██████▉   | 602/872 [00:04<00:02, 111.64it/s, loss=4.4093]\u001B[A\n",
      "Validation:  69%|██████▉   | 602/872 [00:04<00:02, 111.64it/s, loss=4.4094]\u001B[A\n",
      "Validation:  69%|██████▉   | 602/872 [00:04<00:02, 111.64it/s, loss=4.4094]\u001B[A\n",
      "Validation:  69%|██████▉   | 602/872 [00:04<00:02, 111.64it/s, loss=4.4094]\u001B[A\n",
      "Validation:  69%|██████▉   | 602/872 [00:04<00:02, 111.64it/s, loss=4.4092]\u001B[A\n",
      "Validation:  69%|██████▉   | 602/872 [00:04<00:02, 111.64it/s, loss=4.4093]\u001B[A\n",
      "Validation:  69%|██████▉   | 602/872 [00:04<00:02, 111.64it/s, loss=4.4093]\u001B[A\n",
      "Validation:  69%|██████▉   | 602/872 [00:04<00:02, 111.64it/s, loss=4.4093]\u001B[A\n",
      "Validation:  69%|██████▉   | 602/872 [00:04<00:02, 111.64it/s, loss=4.4095]\u001B[A\n",
      "Validation:  70%|███████   | 614/872 [00:04<00:02, 100.56it/s, loss=4.4095]\u001B[A\n",
      "Validation:  70%|███████   | 614/872 [00:04<00:02, 100.56it/s, loss=4.4094]\u001B[A\n",
      "Validation:  70%|███████   | 614/872 [00:04<00:02, 100.56it/s, loss=4.4095]\u001B[A\n",
      "Validation:  70%|███████   | 614/872 [00:04<00:02, 100.56it/s, loss=4.4096]\u001B[A\n",
      "Validation:  70%|███████   | 614/872 [00:04<00:02, 100.56it/s, loss=4.4098]\u001B[A\n",
      "Validation:  70%|███████   | 614/872 [00:04<00:02, 100.56it/s, loss=4.4098]\u001B[A\n",
      "Validation:  70%|███████   | 614/872 [00:04<00:02, 100.56it/s, loss=4.4097]\u001B[A\n",
      "Validation:  70%|███████   | 614/872 [00:05<00:02, 100.56it/s, loss=4.4097]\u001B[A\n",
      "Validation:  70%|███████   | 614/872 [00:05<00:02, 100.56it/s, loss=4.4098]\u001B[A\n",
      "Validation:  70%|███████   | 614/872 [00:05<00:02, 100.56it/s, loss=4.4098]\u001B[A\n",
      "Validation:  70%|███████   | 614/872 [00:05<00:02, 100.56it/s, loss=4.4097]\u001B[A\n",
      "Validation:  70%|███████   | 614/872 [00:05<00:02, 100.56it/s, loss=4.4097]\u001B[A\n",
      "Validation:  72%|███████▏  | 625/872 [00:05<00:02, 92.90it/s, loss=4.4097] \u001B[A\n",
      "Validation:  72%|███████▏  | 625/872 [00:05<00:02, 92.90it/s, loss=4.4095]\u001B[A\n",
      "Validation:  72%|███████▏  | 625/872 [00:05<00:02, 92.90it/s, loss=4.4095]\u001B[A\n",
      "Validation:  72%|███████▏  | 625/872 [00:05<00:02, 92.90it/s, loss=4.4095]\u001B[A\n",
      "Validation:  72%|███████▏  | 625/872 [00:05<00:02, 92.90it/s, loss=4.4096]\u001B[A\n",
      "Validation:  72%|███████▏  | 625/872 [00:05<00:02, 92.90it/s, loss=4.4093]\u001B[A\n",
      "Validation:  72%|███████▏  | 625/872 [00:05<00:02, 92.90it/s, loss=4.4093]\u001B[A\n",
      "Validation:  72%|███████▏  | 625/872 [00:05<00:02, 92.90it/s, loss=4.4093]\u001B[A\n",
      "Validation:  72%|███████▏  | 625/872 [00:05<00:02, 92.90it/s, loss=4.4094]\u001B[A\n",
      "Validation:  72%|███████▏  | 625/872 [00:05<00:02, 92.90it/s, loss=4.4095]\u001B[A\n",
      "Validation:  72%|███████▏  | 625/872 [00:05<00:02, 92.90it/s, loss=4.4096]\u001B[A\n",
      "Validation:  73%|███████▎  | 635/872 [00:05<00:02, 91.16it/s, loss=4.4096]\u001B[A\n",
      "Validation:  73%|███████▎  | 635/872 [00:05<00:02, 91.16it/s, loss=4.4097]\u001B[A\n",
      "Validation:  73%|███████▎  | 635/872 [00:05<00:02, 91.16it/s, loss=4.4097]\u001B[A\n",
      "Validation:  73%|███████▎  | 635/872 [00:05<00:02, 91.16it/s, loss=4.4097]\u001B[A\n",
      "Validation:  73%|███████▎  | 635/872 [00:05<00:02, 91.16it/s, loss=4.4098]\u001B[A\n",
      "Validation:  73%|███████▎  | 635/872 [00:05<00:02, 91.16it/s, loss=4.4097]\u001B[A\n",
      "Validation:  73%|███████▎  | 635/872 [00:05<00:02, 91.16it/s, loss=4.4097]\u001B[A\n",
      "Validation:  73%|███████▎  | 635/872 [00:05<00:02, 91.16it/s, loss=4.4098]\u001B[A\n",
      "Validation:  73%|███████▎  | 635/872 [00:05<00:02, 91.16it/s, loss=4.4097]\u001B[A\n",
      "Validation:  73%|███████▎  | 635/872 [00:05<00:02, 91.16it/s, loss=4.4098]\u001B[A\n",
      "Validation:  73%|███████▎  | 635/872 [00:05<00:02, 91.16it/s, loss=4.4097]\u001B[A\n",
      "Validation:  73%|███████▎  | 635/872 [00:05<00:02, 91.16it/s, loss=4.4096]\u001B[A\n",
      "Validation:  73%|███████▎  | 635/872 [00:05<00:02, 91.16it/s, loss=4.4095]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4095]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4096]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4094]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4095]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4096]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4096]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4096]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4094]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4094]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4095]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4094]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4094]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4095]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4095]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4097]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4096]\u001B[A\n",
      "Validation:  74%|███████▍  | 647/872 [00:05<00:02, 96.98it/s, loss=4.4095]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4095]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4096]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4096]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4095]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4095]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4095]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4096]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4095]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4095]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4095]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4096]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4095]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4095]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4095]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4097]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4098]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4098]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4099]\u001B[A\n",
      "Validation:  76%|███████▌  | 663/872 [00:05<00:01, 112.76it/s, loss=4.4099]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4099]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4100]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4100]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4101]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4100]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4100]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4099]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4100]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4099]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4099]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4098]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4099]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4100]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4099]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4100]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4099]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4098]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4098]\u001B[A\n",
      "Validation:  78%|███████▊  | 681/872 [00:05<00:01, 129.02it/s, loss=4.4097]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4097]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4097]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4097]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4097]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4097]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4096]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4098]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4098]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4099]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4099]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4101]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4100]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4099]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4099]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4101]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4101]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4102]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4101]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4102]\u001B[A\n",
      "Validation:  80%|████████  | 699/872 [00:05<00:01, 142.86it/s, loss=4.4102]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4102]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4101]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4103]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4102]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4101]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4102]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4101]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4101]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4101]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4099]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4099]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4098]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4098]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4100]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4098]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4098]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4097]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4096]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4096]\u001B[A\n",
      "Validation:  82%|████████▏ | 718/872 [00:05<00:00, 154.58it/s, loss=4.4095]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4095]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4094]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4093]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4094]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4094]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4094]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4093]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4093]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4093]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4092]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4092]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4092]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4091]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4091]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4091]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4091]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4090]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4089]\u001B[A\n",
      "Validation:  85%|████████▍ | 737/872 [00:05<00:00, 162.94it/s, loss=4.4089]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4089]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4088]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4088]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4088]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4088]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4088]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4090]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4090]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4090]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4091]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4090]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4090]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4089]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4088]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4089]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4088]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4086]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4086]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4087]\u001B[A\n",
      "Validation:  87%|████████▋ | 755/872 [00:05<00:00, 167.77it/s, loss=4.4086]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:05<00:00, 172.51it/s, loss=4.4086]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:05<00:00, 172.51it/s, loss=4.4087]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4088]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4086]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4084]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4085]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4084]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4083]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4082]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4082]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4082]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4082]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4082]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4082]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4082]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4083]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4081]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4081]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4081]\u001B[A\n",
      "Validation:  89%|████████▉ | 774/872 [00:06<00:00, 172.51it/s, loss=4.4082]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4082]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4082]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4081]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4081]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4081]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4081]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4080]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4080]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4080]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4079]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4080]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4079]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4080]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4080]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4080]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4080]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4080]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4079]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4080]\u001B[A\n",
      "Validation:  91%|█████████ | 793/872 [00:06<00:00, 175.76it/s, loss=4.4080]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4080]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4080]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4080]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4080]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4079]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4078]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4076]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4076]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4075]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4075]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4075]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4075]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4075]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4075]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4076]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4075]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4075]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4074]\u001B[A\n",
      "Validation:  93%|█████████▎| 812/872 [00:06<00:00, 178.71it/s, loss=4.4072]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4072]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4072]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4073]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4072]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4070]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4069]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4069]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4068]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4068]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4068]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4068]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4068]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4068]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4068]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4068]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4066]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4067]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4068]\u001B[A\n",
      "Validation:  95%|█████████▌| 830/872 [00:06<00:00, 178.93it/s, loss=4.4068]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4068]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4068]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4067]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4066]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4066]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4066]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4067]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4066]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4065]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4065]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4064]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4065]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4064]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4063]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4063]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4063]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4063]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4063]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4063]\u001B[A\n",
      "Validation:  97%|█████████▋| 848/872 [00:06<00:00, 179.12it/s, loss=4.4062]\u001B[A\n",
      "Validation:  99%|█████████▉| 867/872 [00:06<00:00, 180.77it/s, loss=4.4062]\u001B[A\n",
      "Validation:  99%|█████████▉| 867/872 [00:06<00:00, 180.77it/s, loss=4.4063]\u001B[A\n",
      "Validation:  99%|█████████▉| 867/872 [00:06<00:00, 180.77it/s, loss=4.4063]\u001B[A\n",
      "Validation:  99%|█████████▉| 867/872 [00:06<00:00, 180.77it/s, loss=4.4061]\u001B[A\n",
      "Validation:  99%|█████████▉| 867/872 [00:06<00:00, 180.77it/s, loss=4.4061]\u001B[A\n",
      "Validation: 100%|██████████| 872/872 [00:06<00:00, 127.23it/s, loss=4.4060]\u001B[A\n",
      "Training:  51%|█████     | 508/1000 [00:17<02:08,  3.82it/s, loss=4.4266]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.4060, Perplexity: 81.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|█████████ | 909/1000 [00:25<00:02, 35.19it/s, loss=4.4097]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m scheduler \u001B[38;5;241m=\u001B[39m setup_scheduler(optimizer, CONFIG\u001B[38;5;241m.\u001B[39mscheduler, CONFIG\u001B[38;5;241m.\u001B[39mwarmup_ratio, \u001B[38;5;28mlen\u001B[39m(train_loader) \u001B[38;5;241m*\u001B[39m CONFIG\u001B[38;5;241m.\u001B[39mmax_steps)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Train model\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m train_steps(model, train_loader, val_loader, optimizer, scheduler, CONFIG\u001B[38;5;241m.\u001B[39mmax_steps, CONFIG\u001B[38;5;241m.\u001B[39mval_interval, CONFIG\u001B[38;5;241m.\u001B[39mgrad_clip, CONFIG\u001B[38;5;241m.\u001B[39mdevice, wandb_run)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Finish wandb run\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m wandb_run \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/GitHub/LLM101/src/train.py:453\u001B[0m, in \u001B[0;36mtrain_steps\u001B[0;34m(model, train_loader, val_loader, optimizer, scheduler, max_steps, val_interval, grad_clip, device, wandb_run)\u001B[0m\n\u001B[1;32m    451\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m    452\u001B[0m clip_grad_norm_(model\u001B[38;5;241m.\u001B[39mparameters(), grad_clip)\n\u001B[0;32m--> 453\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m    454\u001B[0m scheduler\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m    455\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:137\u001B[0m, in \u001B[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    135\u001B[0m opt \u001B[38;5;241m=\u001B[39m opt_ref()\n\u001B[1;32m    136\u001B[0m opt\u001B[38;5;241m.\u001B[39m_opt_called \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[union-attr]\u001B[39;00m\n\u001B[0;32m--> 137\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__get__\u001B[39m(opt, opt\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.12/site-packages/torch/optim/optimizer.py:487\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    482\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    483\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    484\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    485\u001B[0m             )\n\u001B[0;32m--> 487\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    488\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    490\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     89\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     90\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 91\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     93\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.12/site-packages/torch/optim/adamw.py:220\u001B[0m, in \u001B[0;36mAdamW.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    207\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m cast(Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m], group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    209\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    210\u001B[0m         group,\n\u001B[1;32m    211\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    217\u001B[0m         state_steps,\n\u001B[1;32m    218\u001B[0m     )\n\u001B[0;32m--> 220\u001B[0m     adamw(\n\u001B[1;32m    221\u001B[0m         params_with_grad,\n\u001B[1;32m    222\u001B[0m         grads,\n\u001B[1;32m    223\u001B[0m         exp_avgs,\n\u001B[1;32m    224\u001B[0m         exp_avg_sqs,\n\u001B[1;32m    225\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    226\u001B[0m         state_steps,\n\u001B[1;32m    227\u001B[0m         amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[1;32m    228\u001B[0m         beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[1;32m    229\u001B[0m         beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[1;32m    230\u001B[0m         lr\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    231\u001B[0m         weight_decay\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight_decay\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    232\u001B[0m         eps\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meps\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    233\u001B[0m         maximize\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    234\u001B[0m         foreach\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforeach\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    235\u001B[0m         capturable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    236\u001B[0m         differentiable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    237\u001B[0m         fused\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfused\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    238\u001B[0m         grad_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad_scale\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    239\u001B[0m         found_inf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    240\u001B[0m         has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[1;32m    241\u001B[0m     )\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001B[0m, in \u001B[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.12/site-packages/torch/optim/adamw.py:782\u001B[0m, in \u001B[0;36madamw\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    779\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    780\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adamw\n\u001B[0;32m--> 782\u001B[0m func(\n\u001B[1;32m    783\u001B[0m     params,\n\u001B[1;32m    784\u001B[0m     grads,\n\u001B[1;32m    785\u001B[0m     exp_avgs,\n\u001B[1;32m    786\u001B[0m     exp_avg_sqs,\n\u001B[1;32m    787\u001B[0m     max_exp_avg_sqs,\n\u001B[1;32m    788\u001B[0m     state_steps,\n\u001B[1;32m    789\u001B[0m     amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[1;32m    790\u001B[0m     beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[1;32m    791\u001B[0m     beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[1;32m    792\u001B[0m     lr\u001B[38;5;241m=\u001B[39mlr,\n\u001B[1;32m    793\u001B[0m     weight_decay\u001B[38;5;241m=\u001B[39mweight_decay,\n\u001B[1;32m    794\u001B[0m     eps\u001B[38;5;241m=\u001B[39meps,\n\u001B[1;32m    795\u001B[0m     maximize\u001B[38;5;241m=\u001B[39mmaximize,\n\u001B[1;32m    796\u001B[0m     capturable\u001B[38;5;241m=\u001B[39mcapturable,\n\u001B[1;32m    797\u001B[0m     differentiable\u001B[38;5;241m=\u001B[39mdifferentiable,\n\u001B[1;32m    798\u001B[0m     grad_scale\u001B[38;5;241m=\u001B[39mgrad_scale,\n\u001B[1;32m    799\u001B[0m     found_inf\u001B[38;5;241m=\u001B[39mfound_inf,\n\u001B[1;32m    800\u001B[0m     has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[1;32m    801\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.12/site-packages/torch/optim/adamw.py:372\u001B[0m, in \u001B[0;36m_single_tensor_adamw\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001B[0m\n\u001B[1;32m    369\u001B[0m step_t \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;66;03m# Perform stepweight decay\u001B[39;00m\n\u001B[0;32m--> 372\u001B[0m param\u001B[38;5;241m.\u001B[39mmul_(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m lr \u001B[38;5;241m*\u001B[39m weight_decay)\n\u001B[1;32m    374\u001B[0m \u001B[38;5;66;03m# Decay the first and second moment running average coefficient\u001B[39;00m\n\u001B[1;32m    375\u001B[0m exp_avg\u001B[38;5;241m.\u001B[39mlerp_(grad, \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta1)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
