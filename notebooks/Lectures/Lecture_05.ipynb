{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lecture 5: Convolutional Neural Networks\n",
    "\n",
    "In this lecture, we will introduce Convolutional Neural Networks (CNN).\n",
    "\n",
    "CNN architecture is widely used in image recognition tasks. However, it can also be used in other domains such as Natural Language Processing and speech recognition. Let's focus on the application in NLP and reproduce WaveNet.\n",
    "\n",
    "CNN papers:\n",
    "- LeNet: [LeCun et al. 1989](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)\n",
    "- AlexNet: [Krizhevsky et al. 2012](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n",
    "- WaveNet: [van den Oord et al. 2016](https://arxiv.org/pdf/1609.03499)"
   ],
   "id": "f598c4dea3f218e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries",
   "id": "7f89f5b0848c0910"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:43.494969Z",
     "start_time": "2025-02-10T06:03:40.846024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import itertools\n",
    "from dataclasses import dataclass\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "import wandb\n",
    "from src.utils import load_text, set_seed, configure_device"
   ],
   "id": "bc3504580e90bbb4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "3e47af9eb5496281"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:43.506205Z",
     "start_time": "2025-02-10T06:03:43.502059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class CNNConfig:\n",
    "    root_dir: str = os.getcwd() + \"/../../\"\n",
    "    dataset_path: str = \"data/names.txt\"\n",
    "    device: torch.device = torch.device('cpu')  # Automatic device configuration\n",
    "\n",
    "    # Tokenizer\n",
    "    vocab_size: int = 0  # Set later\n",
    "\n",
    "    # Model\n",
    "    context_size: int = 8  # Increase the context size to 8\n",
    "\n",
    "    # Training\n",
    "    val_size: float = 0.1\n",
    "    batch_size: int = 32\n",
    "    max_steps: int = 10000\n",
    "    lr: float = 0.01\n",
    "    val_interval: int = 100\n",
    "    log_interval: int = 100\n",
    "\n",
    "    seed: int = 101"
   ],
   "id": "ecf1ccb60511beaf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Weights & Biases",
   "id": "5341ab83663dd1a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:45.264577Z",
     "start_time": "2025-02-10T06:03:43.600668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wandb.login(key=os.environ.get(\"WANDB_API_KEY\"))\n",
    "wandb.init(\n",
    "    project=\"lecture-05\",\n",
    "    config={\n",
    "        \"context_size\": CNNConfig.context_size,\n",
    "    },\n",
    "    dir=CNNConfig.root_dir\n",
    ")"
   ],
   "id": "1dbf084fc557fd86",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpathfinderkr\u001B[0m to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/Users/pathfinder/Documents/GitHub/LLM101/notebooks/Lectures/../../wandb/run-20250210_150344-0vctypke</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pathfinderkr/lecture-05/runs/0vctypke' target=\"_blank\">fearless-oath-1</a></strong> to <a href='https://wandb.ai/pathfinderkr/lecture-05' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/pathfinderkr/lecture-05' target=\"_blank\">https://wandb.ai/pathfinderkr/lecture-05</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/pathfinderkr/lecture-05/runs/0vctypke' target=\"_blank\">https://wandb.ai/pathfinderkr/lecture-05/runs/0vctypke</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/pathfinderkr/lecture-05/runs/0vctypke?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x10ee7d8e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reproducibility",
   "id": "502877238c748ea7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:45.868174Z",
     "start_time": "2025-02-10T06:03:45.851788Z"
    }
   },
   "cell_type": "code",
   "source": "set_seed(CNNConfig.seed)",
   "id": "33f4a4fc4e01baa3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 101\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "2d829760e5a2941"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:45.952707Z",
     "start_time": "2025-02-10T06:03:45.915974Z"
    }
   },
   "cell_type": "code",
   "source": "CNNConfig.device = configure_device()",
   "id": "7adb7527962b2cc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on mps\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "ab30418942b02be8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:45.993730Z",
     "start_time": "2025-02-10T06:03:45.984211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load text and split by lines\n",
    "names = load_text(CNNConfig.root_dir + CNNConfig.dataset_path).splitlines()"
   ],
   "id": "3d8796ce3f291e5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text data from /Users/pathfinder/Documents/GitHub/LLM101/notebooks/Lectures/../../data/names.txt (length: 228145 characters).\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizer",
   "id": "d66e73f17af528d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:46.033321Z",
     "start_time": "2025-02-10T06:03:46.028262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chars = [chr(i) for i in range(97, 123)]  # all alphabet characters\n",
    "chars.insert(0, \".\")  # Add special token\n",
    "CNNConfig.vocab_size = len(chars)\n",
    "str2idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx2str = {idx: char for char, idx in str2idx.items()}"
   ],
   "id": "ee51763de0b3a997",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "f105045be1317feb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:46.080730Z",
     "start_time": "2025-02-10T06:03:46.067415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train-Val Split\n",
    "train_names, val_names = train_test_split(names, test_size=CNNConfig.val_size, random_state=CNNConfig.seed)"
   ],
   "id": "7ab75bfb450734ac",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:46.376363Z",
     "start_time": "2025-02-10T06:03:46.101057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset and DataLoader\n",
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, _names, context_size):\n",
    "        self.inputs, self.targets = [], []\n",
    "\n",
    "        for name in _names:\n",
    "            context = [0] * context_size\n",
    "\n",
    "            for char in name + \".\":\n",
    "                idx = str2idx[char]\n",
    "                self.inputs.append(context)\n",
    "                self.targets.append(idx)\n",
    "                context = context[1:] + [idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = torch.tensor(self.inputs[idx])\n",
    "        target_id = torch.tensor(self.targets[idx])\n",
    "        return input_ids, target_id\n",
    "\n",
    "train_dataset = NamesDataset(train_names, context_size=CNNConfig.context_size)\n",
    "val_dataset = NamesDataset(val_names, context_size=CNNConfig.context_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CNNConfig.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CNNConfig.batch_size, shuffle=False)"
   ],
   "id": "8416195bc2d97f4e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:46.387866Z",
     "start_time": "2025-02-10T06:03:46.381849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualize the dataset\n",
    "for i in range(20):\n",
    "    context, target = train_dataset[i]\n",
    "    context_str = ''.join([idx2str[int(token)] for token in context])\n",
    "    target_char = idx2str[int(target)]\n",
    "    print(f\"{context_str} --> {target_char}\")"
   ],
   "id": "5cc608e739e99fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ --> k\n",
      ".......k --> e\n",
      "......ke --> y\n",
      ".....key --> l\n",
      "....keyl --> e\n",
      "...keyle --> r\n",
      "..keyler --> .\n",
      "........ --> t\n",
      ".......t --> i\n",
      "......ti --> t\n",
      ".....tit --> u\n",
      "....titu --> s\n",
      "...titus --> .\n",
      "........ --> r\n",
      ".......r --> y\n",
      "......ry --> l\n",
      ".....ryl --> i\n",
      "....ryli --> .\n",
      "........ --> j\n",
      ".......j --> a\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "fe4a0a60f3f91af4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Multi-Layer Perceptron (MLP)\n",
    "\n",
    "Let's discuss the architecture of a Multi-Layer Perceptron (MLP).\n",
    "\n",
    "![MLP](../../assets/mlp.png)\n",
    "\n",
    "Q1: How do the embedding tokens communicate with each other? What operation is performed to do so?\n",
    "\n",
    "Q2: Let's increase the context size to 16, 64, ... What are the restrictions of increasing the context size?\n",
    "\n"
   ],
   "id": "3c0f1b9715cc66c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:46.403638Z",
     "start_time": "2025-02-10T06:03:46.399249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Implement the MLP model.                                                     #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, context_size, d_embed, d_hidden):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.linear1 = nn.Linear(context_size * d_embed, d_hidden, bias=True)\n",
    "        self.linear2 = nn.Linear(d_hidden, vocab_size, bias=True)\n",
    "\n",
    "    def forward(self, x):  # x: (batch_size, context_size)\n",
    "        x_embed = self.embedding(x)  # (batch_size, context_size, d_embed)\n",
    "        x_embed = x_embed.view(x_embed.size(0), -1)  # (batch_size, context_size * d_embed)\n",
    "        x = F.relu(self.linear1(x_embed))  # (batch_size, d_hidden)\n",
    "        x = self.linear2(x)  # (batch_size, vocab_size)\n",
    "        return x\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
   ],
   "id": "f36c4f39c0cfaf5b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:46.444892Z",
     "start_time": "2025-02-10T06:03:46.417458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "mlp = MLP(CNNConfig.vocab_size, CNNConfig.context_size, d_embed=16, d_hidden=64)\n",
    "mlp.to(CNNConfig.device)\n",
    "print(mlp)\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in mlp.parameters()))"
   ],
   "id": "c1f99922f7469709",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (embedding): Embedding(27, 16)\n",
      "  (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (linear2): Linear(in_features=64, out_features=27, bias=True)\n",
      ")\n",
      "Number of parameters: 10443\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:04:11.347689Z",
     "start_time": "2025-02-10T06:04:11.333322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "def train(\n",
    "        model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        max_steps: int,\n",
    "        lr: float,\n",
    "        val_interval: int,\n",
    "        log_interval: int,\n",
    "        device: torch.device,\n",
    "        wandb_run: wandb.sdk.wandb_run.Run\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the model for a fixed number of steps.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        train_loader (DataLoader): DataLoader for the training data.\n",
    "        val_loader (DataLoader): DataLoader for the validation data.\n",
    "        max_steps (int): Maximum number of steps to train.\n",
    "        lr (float): Learning rate.\n",
    "        val_interval (int): Interval for validation.\n",
    "        log_interval (int): Interval for logging.\n",
    "        device (torch.device): Device to run the model on.\n",
    "        wandb_run (wandb.sdk.wandb_run.Run): Wandb run for logging.\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # Optimizer\n",
    "\n",
    "    running_loss = 0.0\n",
    "    step = 1\n",
    "    train_iter = itertools.cycle(train_loader)  # Infinite dataloader\n",
    "    progress_bar = tqdm(total=max_steps, desc=\"Training\", leave=True)\n",
    "\n",
    "    if wandb_run is not None:\n",
    "        wandb.watch(model, log=\"all\", log_freq=log_interval)\n",
    "\n",
    "    while step <= max_steps:\n",
    "        model.train()\n",
    "        train_inputs, train_targets = next(train_iter)\n",
    "        train_inputs, train_targets = train_inputs.to(device), train_targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(train_inputs)\n",
    "        loss = F.cross_entropy(logits, train_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=f\"{running_loss / step:.4f}\")\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        if step % val_interval == 0:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            total_samples = 0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_targets in val_loader:\n",
    "                    val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                    val_logits = model(val_inputs)\n",
    "                    batch_loss = F.cross_entropy(val_logits, val_targets)\n",
    "                    val_loss += batch_loss.item() * val_inputs.size(0)\n",
    "                    total_samples += val_inputs.size(0)\n",
    "\n",
    "            #print(f\"Step {step}: Train Loss = {running_loss / step:.4f}, Val Loss = {val_loss / total_samples:.4f}\")\n",
    "            if wandb_run is not None:\n",
    "                wandb.log({\"Val Loss\": val_loss / total_samples})\n",
    "\n",
    "        if step % log_interval == 0:\n",
    "                if wandb_run is not None:\n",
    "                    wandb.log({\"Train Loss\": running_loss / step})\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    progress_bar.close()\n",
    "    if wandb_run is not None:\n",
    "        wandb_run.finish()"
   ],
   "id": "d39785fb1d5b50bc",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-10T06:04:12.035645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train(\n",
    "    model=mlp,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    max_steps=CNNConfig.max_steps,\n",
    "    lr=CNNConfig.lr,\n",
    "    val_interval=CNNConfig.val_interval,\n",
    "    log_interval=CNNConfig.log_interval,\n",
    "    device=CNNConfig.device,\n",
    "    wandb_run=wandb.run\n",
    ")"
   ],
   "id": "47a9e92b0eff104e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/10000 [00:00<?, ?it/s]\u001B[A\n",
      "Training:   0%|          | 0/10000 [00:01<?, ?it/s, loss=3.3361]\u001B[A\n",
      "Training:   0%|          | 1/10000 [00:01<2:55:56,  1.06s/it, loss=3.3361]\u001B[A\n",
      "Training:   0%|          | 1/10000 [00:01<2:55:56,  1.06s/it, loss=3.2566]\u001B[A\n",
      "Training:   0%|          | 2/10000 [00:01<2:55:55,  1.06s/it, loss=3.1666]\u001B[A\n",
      "Training:   0%|          | 3/10000 [00:01<2:55:54,  1.06s/it, loss=3.0745]\u001B[A\n",
      "Training:   0%|          | 4/10000 [00:01<2:55:53,  1.06s/it, loss=3.0704]\u001B[A\n",
      "Training:   0%|          | 5/10000 [00:01<29:57,  5.56it/s, loss=3.0704]  \u001B[A\n",
      "Training:   0%|          | 5/10000 [00:01<29:57,  5.56it/s, loss=3.0520]\u001B[A\n",
      "Training:   0%|          | 6/10000 [00:01<29:57,  5.56it/s, loss=3.0169]\u001B[A\n",
      "Training:   0%|          | 7/10000 [00:01<29:57,  5.56it/s, loss=3.0600]\u001B[A\n",
      "Training:   0%|          | 8/10000 [00:01<29:57,  5.56it/s, loss=3.0348]\u001B[A\n",
      "Training:   0%|          | 9/10000 [00:01<29:57,  5.56it/s, loss=2.9826]\u001B[A\n",
      "Training:   0%|          | 10/10000 [00:01<29:57,  5.56it/s, loss=2.9838]\u001B[A\n",
      "Training:   0%|          | 11/10000 [00:01<29:56,  5.56it/s, loss=2.9702]\u001B[A\n",
      "Training:   0%|          | 12/10000 [00:01<29:56,  5.56it/s, loss=2.9485]\u001B[A\n",
      "Training:   0%|          | 13/10000 [00:01<10:13, 16.28it/s, loss=2.9485]\u001B[A\n",
      "Training:   0%|          | 13/10000 [00:01<10:13, 16.28it/s, loss=2.9325]\u001B[A\n",
      "Training:   0%|          | 14/10000 [00:01<10:13, 16.28it/s, loss=2.9060]\u001B[A\n",
      "Training:   0%|          | 15/10000 [00:01<10:13, 16.28it/s, loss=2.8910]\u001B[A\n",
      "Training:   0%|          | 16/10000 [00:01<10:13, 16.28it/s, loss=2.8852]\u001B[A\n",
      "Training:   0%|          | 17/10000 [00:01<10:13, 16.28it/s, loss=2.8735]\u001B[A\n",
      "Training:   0%|          | 18/10000 [00:01<10:12, 16.28it/s, loss=2.8909]\u001B[A\n",
      "Training:   0%|          | 19/10000 [00:01<10:12, 16.28it/s, loss=2.8753]\u001B[A\n",
      "Training:   0%|          | 20/10000 [00:01<10:12, 16.28it/s, loss=2.8833]\u001B[A\n",
      "Training:   0%|          | 21/10000 [00:01<10:12, 16.28it/s, loss=2.8740]\u001B[A\n",
      "Training:   0%|          | 22/10000 [00:01<05:52, 28.30it/s, loss=2.8740]\u001B[A\n",
      "Training:   0%|          | 22/10000 [00:01<05:52, 28.30it/s, loss=2.8658]\u001B[A\n",
      "Training:   0%|          | 23/10000 [00:01<05:52, 28.30it/s, loss=2.8525]\u001B[A\n",
      "Training:   0%|          | 24/10000 [00:01<05:52, 28.30it/s, loss=2.8462]\u001B[A\n",
      "Training:   0%|          | 25/10000 [00:01<05:52, 28.30it/s, loss=2.8392]\u001B[A\n",
      "Training:   0%|          | 26/10000 [00:01<05:52, 28.30it/s, loss=2.8311]\u001B[A\n",
      "Training:   0%|          | 27/10000 [00:01<05:52, 28.30it/s, loss=2.8211]\u001B[A\n",
      "Training:   0%|          | 28/10000 [00:01<05:52, 28.30it/s, loss=2.8125]\u001B[A\n",
      "Training:   0%|          | 29/10000 [00:01<05:52, 28.30it/s, loss=2.8057]\u001B[A\n",
      "Training:   0%|          | 30/10000 [00:01<05:52, 28.30it/s, loss=2.8026]\u001B[A\n",
      "Training:   0%|          | 31/10000 [00:01<05:52, 28.30it/s, loss=2.7966]\u001B[A\n",
      "Training:   0%|          | 32/10000 [00:01<04:00, 41.38it/s, loss=2.7966]\u001B[A\n",
      "Training:   0%|          | 32/10000 [00:01<04:00, 41.38it/s, loss=2.7786]\u001B[A\n",
      "Training:   0%|          | 33/10000 [00:01<04:00, 41.38it/s, loss=2.7612]\u001B[A\n",
      "Training:   0%|          | 34/10000 [00:01<04:00, 41.38it/s, loss=2.7664]\u001B[A\n",
      "Training:   0%|          | 35/10000 [00:01<04:00, 41.38it/s, loss=2.7619]\u001B[A\n",
      "Training:   0%|          | 36/10000 [00:01<04:00, 41.38it/s, loss=2.7504]\u001B[A\n",
      "Training:   0%|          | 37/10000 [00:01<04:00, 41.38it/s, loss=2.7448]\u001B[A\n",
      "Training:   0%|          | 38/10000 [00:01<04:00, 41.38it/s, loss=2.7436]\u001B[A\n",
      "Training:   0%|          | 39/10000 [00:01<04:00, 41.38it/s, loss=2.7472]\u001B[A\n",
      "Training:   0%|          | 40/10000 [00:01<04:00, 41.38it/s, loss=2.7501]\u001B[A\n",
      "Training:   0%|          | 41/10000 [00:01<04:00, 41.38it/s, loss=2.7440]\u001B[A\n",
      "Training:   0%|          | 42/10000 [00:01<03:05, 53.65it/s, loss=2.7440]\u001B[A\n",
      "Training:   0%|          | 42/10000 [00:01<03:05, 53.65it/s, loss=2.7403]\u001B[A\n",
      "Training:   0%|          | 43/10000 [00:01<03:05, 53.65it/s, loss=2.7353]\u001B[A\n",
      "Training:   0%|          | 44/10000 [00:01<03:05, 53.65it/s, loss=2.7386]\u001B[A\n",
      "Training:   0%|          | 45/10000 [00:01<03:05, 53.65it/s, loss=2.7377]\u001B[A\n",
      "Training:   0%|          | 46/10000 [00:01<03:05, 53.65it/s, loss=2.7400]\u001B[A\n",
      "Training:   0%|          | 47/10000 [00:01<03:05, 53.65it/s, loss=2.7409]\u001B[A\n",
      "Training:   0%|          | 48/10000 [00:01<03:05, 53.65it/s, loss=2.7365]\u001B[A\n",
      "Training:   0%|          | 49/10000 [00:01<03:05, 53.65it/s, loss=2.7332]\u001B[A\n",
      "Training:   0%|          | 50/10000 [00:01<03:05, 53.65it/s, loss=2.7320]\u001B[A\n",
      "Training:   1%|          | 51/10000 [00:01<03:05, 53.65it/s, loss=2.7283]\u001B[A\n",
      "Training:   1%|          | 52/10000 [00:01<03:05, 53.65it/s, loss=2.7240]\u001B[A\n",
      "Training:   1%|          | 53/10000 [00:01<03:05, 53.65it/s, loss=2.7242]\u001B[A\n",
      "Training:   1%|          | 54/10000 [00:01<02:25, 68.36it/s, loss=2.7242]\u001B[A\n",
      "Training:   1%|          | 54/10000 [00:01<02:25, 68.36it/s, loss=2.7198]\u001B[A\n",
      "Training:   1%|          | 55/10000 [00:01<02:25, 68.36it/s, loss=2.7151]\u001B[A\n",
      "Training:   1%|          | 56/10000 [00:01<02:25, 68.36it/s, loss=2.7175]\u001B[A\n",
      "Training:   1%|          | 57/10000 [00:01<02:25, 68.36it/s, loss=2.7180]\u001B[A\n",
      "Training:   1%|          | 58/10000 [00:01<02:25, 68.36it/s, loss=2.7181]\u001B[A\n",
      "Training:   1%|          | 59/10000 [00:01<02:25, 68.36it/s, loss=2.7174]\u001B[A\n",
      "Training:   1%|          | 60/10000 [00:01<02:25, 68.36it/s, loss=2.7151]\u001B[A\n",
      "Training:   1%|          | 61/10000 [00:01<02:25, 68.36it/s, loss=2.7141]\u001B[A\n",
      "Training:   1%|          | 62/10000 [00:01<02:25, 68.36it/s, loss=2.7109]\u001B[A\n",
      "Training:   1%|          | 63/10000 [00:01<02:25, 68.36it/s, loss=2.7108]\u001B[A\n",
      "Training:   1%|          | 64/10000 [00:01<02:25, 68.36it/s, loss=2.7095]\u001B[A\n",
      "Training:   1%|          | 65/10000 [00:01<02:25, 68.36it/s, loss=2.7043]\u001B[A\n",
      "Training:   1%|          | 66/10000 [00:01<02:25, 68.36it/s, loss=2.7049]\u001B[A\n",
      "Training:   1%|          | 67/10000 [00:01<02:06, 78.26it/s, loss=2.7049]\u001B[A\n",
      "Training:   1%|          | 67/10000 [00:01<02:06, 78.26it/s, loss=2.7048]\u001B[A\n",
      "Training:   1%|          | 68/10000 [00:01<02:06, 78.26it/s, loss=2.7026]\u001B[A\n",
      "Training:   1%|          | 69/10000 [00:01<02:06, 78.26it/s, loss=2.7051]\u001B[A\n",
      "Training:   1%|          | 70/10000 [00:01<02:06, 78.26it/s, loss=2.7056]\u001B[A\n",
      "Training:   1%|          | 71/10000 [00:01<02:06, 78.26it/s, loss=2.6960]\u001B[A\n",
      "Training:   1%|          | 72/10000 [00:01<02:06, 78.26it/s, loss=2.6985]\u001B[A\n",
      "Training:   1%|          | 73/10000 [00:01<02:06, 78.26it/s, loss=2.7009]\u001B[A\n",
      "Training:   1%|          | 74/10000 [00:01<02:06, 78.26it/s, loss=2.6973]\u001B[A\n",
      "Training:   1%|          | 75/10000 [00:01<02:06, 78.26it/s, loss=2.6945]\u001B[A\n",
      "Training:   1%|          | 76/10000 [00:01<02:06, 78.26it/s, loss=2.6914]\u001B[A\n",
      "Training:   1%|          | 77/10000 [00:01<02:13, 74.47it/s, loss=2.6914]\u001B[A\n",
      "Training:   1%|          | 77/10000 [00:01<02:13, 74.47it/s, loss=2.6908]\u001B[A\n",
      "Training:   1%|          | 78/10000 [00:01<02:13, 74.47it/s, loss=2.6858]\u001B[A\n",
      "Training:   1%|          | 79/10000 [00:02<02:13, 74.47it/s, loss=2.6825]\u001B[A\n",
      "Training:   1%|          | 80/10000 [00:02<02:13, 74.47it/s, loss=2.6803]\u001B[A\n",
      "Training:   1%|          | 81/10000 [00:02<02:13, 74.47it/s, loss=2.6749]\u001B[A\n",
      "Training:   1%|          | 82/10000 [00:02<02:13, 74.47it/s, loss=2.6752]\u001B[A\n",
      "Training:   1%|          | 83/10000 [00:02<02:13, 74.47it/s, loss=2.6711]\u001B[A\n",
      "Training:   1%|          | 84/10000 [00:02<02:13, 74.47it/s, loss=2.6695]\u001B[A\n",
      "Training:   1%|          | 85/10000 [00:02<02:13, 74.47it/s, loss=2.6688]\u001B[A\n",
      "Training:   1%|          | 86/10000 [00:02<02:12, 74.94it/s, loss=2.6688]\u001B[A\n",
      "Training:   1%|          | 86/10000 [00:02<02:12, 74.94it/s, loss=2.6652]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:47.540363Z",
     "start_time": "2025-02-10T05:33:52.004669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Write your answer to the questions above.                                    #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "# A1:\n",
    "# A2:\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
   ],
   "id": "ab549d775a5e8c73",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Convolutional Neural Network (CNN)\n",
    "\n",
    "![WaveNet](../../assets/wavenet.png)\n",
    "\n",
    "Instead of connecting each token to all other tokens, CNN uses convolutional layers to connect tokens within a certain range.\n",
    "\n",
    "Example:\n",
    "- Layer 1: 8 vectors\n",
    "- Layer 2: 4 vectors\n",
    "- Layer 3: 2 vectors\n",
    "- Layer 4: 1 vector\n"
   ],
   "id": "ddf42ba9322c757d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T06:03:48.107847Z",
     "start_time": "2025-02-10T05:33:52.053517Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b123cc3389bfe396",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
