{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lecture 5: Convolutional Neural Networks\n",
    "\n",
    "In this lecture, we will introduce Convolutional Neural Networks (CNN).\n",
    "\n",
    "CNN architecture is widely used in image recognition tasks. However, it can also be used in other domains such as Natural Language Processing and speech recognition. Let's focus on the application in NLP and reproduce WaveNet.\n",
    "\n",
    "CNN papers:\n",
    "- LeNet: [LeCun et al. 1989](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)\n",
    "- AlexNet: [Krizhevsky et al. 2012](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n",
    "- WaveNet: [van den Oord et al. 2016](https://arxiv.org/pdf/1609.03499)"
   ],
   "id": "f598c4dea3f218e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries",
   "id": "7f89f5b0848c0910"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:03:27.063848Z",
     "start_time": "2025-02-10T07:03:23.472969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import math\n",
    "import itertools\n",
    "from dataclasses import dataclass\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "import wandb\n",
    "from src.utils import load_text, set_seed, configure_device"
   ],
   "id": "bc3504580e90bbb4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "3e47af9eb5496281"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:03:27.504348Z",
     "start_time": "2025-02-10T07:03:27.467534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class CNNConfig:\n",
    "    root_dir: str = os.getcwd() + \"/../../\"\n",
    "    dataset_path: str = \"data/names.txt\"\n",
    "    device: torch.device = torch.device('cpu')  # Automatic device configuration\n",
    "\n",
    "    # Tokenizer\n",
    "    vocab_size: int = 0  # Set later\n",
    "\n",
    "    # Model\n",
    "    context_size: int = 16  # Increase the context size to 16\n",
    "    d_embed: int = 8\n",
    "    d_hidden: int = 64\n",
    "\n",
    "    # Training\n",
    "    val_size: float = 0.1\n",
    "    batch_size: int = 32\n",
    "    max_steps: int = 10000\n",
    "    lr: float = 0.01\n",
    "    val_interval: int = 100\n",
    "    log_interval: int = 100\n",
    "\n",
    "    seed: int = 101"
   ],
   "id": "ecf1ccb60511beaf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Weights & Biases",
   "id": "5341ab83663dd1a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:03:29.742383Z",
     "start_time": "2025-02-10T07:03:27.593856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wandb.login(key=os.environ.get(\"WANDB_API_KEY\"))\n",
    "wandb.init(\n",
    "    project=\"lecture-05\",\n",
    "    dir=CNNConfig.root_dir\n",
    ")"
   ],
   "id": "1dbf084fc557fd86",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpathfinderkr\u001B[0m to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/Users/pathfinder/Documents/GitHub/LLM101/notebooks/Lectures/../../wandb/run-20250210_160328-kjtd7vh0</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pathfinderkr/lecture-05/runs/kjtd7vh0' target=\"_blank\">dulcet-field-3</a></strong> to <a href='https://wandb.ai/pathfinderkr/lecture-05' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/pathfinderkr/lecture-05' target=\"_blank\">https://wandb.ai/pathfinderkr/lecture-05</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/pathfinderkr/lecture-05/runs/kjtd7vh0' target=\"_blank\">https://wandb.ai/pathfinderkr/lecture-05/runs/kjtd7vh0</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/pathfinderkr/lecture-05/runs/kjtd7vh0?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1399d5220>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reproducibility",
   "id": "502877238c748ea7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:03:29.822483Z",
     "start_time": "2025-02-10T07:03:29.795978Z"
    }
   },
   "cell_type": "code",
   "source": "set_seed(CNNConfig.seed)",
   "id": "33f4a4fc4e01baa3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 101\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "2d829760e5a2941"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:03:29.925411Z",
     "start_time": "2025-02-10T07:03:29.889850Z"
    }
   },
   "cell_type": "code",
   "source": "CNNConfig.device = configure_device()",
   "id": "7adb7527962b2cc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on mps\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "ab30418942b02be8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:03:29.976732Z",
     "start_time": "2025-02-10T07:03:29.966116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load text and split by lines\n",
    "names = load_text(CNNConfig.root_dir + CNNConfig.dataset_path).splitlines()"
   ],
   "id": "3d8796ce3f291e5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text data from /Users/pathfinder/Documents/GitHub/LLM101/notebooks/Lectures/../../data/names.txt (length: 228145 characters).\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizer",
   "id": "d66e73f17af528d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:03:30.018043Z",
     "start_time": "2025-02-10T07:03:30.011960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chars = [chr(i) for i in range(97, 123)]  # all alphabet characters\n",
    "chars.insert(0, \".\")  # Add special token\n",
    "CNNConfig.vocab_size = len(chars)\n",
    "str2idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx2str = {idx: char for char, idx in str2idx.items()}"
   ],
   "id": "ee51763de0b3a997",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "f105045be1317feb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:03:30.048425Z",
     "start_time": "2025-02-10T07:03:30.038042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train-Val Split\n",
    "train_names, val_names = train_test_split(names, test_size=CNNConfig.val_size, random_state=CNNConfig.seed)"
   ],
   "id": "7ab75bfb450734ac",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:03:30.525435Z",
     "start_time": "2025-02-10T07:03:30.054705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset and DataLoader\n",
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, _names, context_size):\n",
    "        self.inputs, self.targets = [], []\n",
    "\n",
    "        for name in _names:\n",
    "            context = [0] * context_size\n",
    "\n",
    "            for char in name + \".\":\n",
    "                idx = str2idx[char]\n",
    "                self.inputs.append(context)\n",
    "                self.targets.append(idx)\n",
    "                context = context[1:] + [idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = torch.tensor(self.inputs[idx])\n",
    "        target_id = torch.tensor(self.targets[idx])\n",
    "        return input_ids, target_id\n",
    "\n",
    "train_dataset = NamesDataset(train_names, context_size=CNNConfig.context_size)\n",
    "val_dataset = NamesDataset(val_names, context_size=CNNConfig.context_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CNNConfig.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CNNConfig.batch_size, shuffle=False)"
   ],
   "id": "8416195bc2d97f4e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:03:30.616846Z",
     "start_time": "2025-02-10T07:03:30.601051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualize the dataset\n",
    "for i in range(20):\n",
    "    context, target = train_dataset[i]\n",
    "    context_str = ''.join([idx2str[int(token)] for token in context])\n",
    "    target_char = idx2str[int(target)]\n",
    "    print(f\"{context_str} --> {target_char}\")"
   ],
   "id": "5cc608e739e99fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ --> k\n",
      ".......k --> e\n",
      "......ke --> y\n",
      ".....key --> l\n",
      "....keyl --> e\n",
      "...keyle --> r\n",
      "..keyler --> .\n",
      "........ --> t\n",
      ".......t --> i\n",
      "......ti --> t\n",
      ".....tit --> u\n",
      "....titu --> s\n",
      "...titus --> .\n",
      "........ --> r\n",
      ".......r --> y\n",
      "......ry --> l\n",
      ".....ryl --> i\n",
      "....ryli --> .\n",
      "........ --> j\n",
      ".......j --> a\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "fe4a0a60f3f91af4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Multi-Layer Perceptron (MLP)\n",
    "\n",
    "Let's discuss the architecture of a Multi-Layer Perceptron (MLP).\n",
    "\n",
    "![MLP](../../assets/mlp.png)\n",
    "\n",
    "Q1: How do the embedding tokens communicate with each other? What operation is performed to do so?\n",
    "\n",
    "Q2: Imagine having a context size of 3 when using ChatGPT... Let's increase the context size to 128, 1024, etc. What would be the challenges in this MLP architecture?\n",
    "\n"
   ],
   "id": "3c0f1b9715cc66c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:03:30.667722Z",
     "start_time": "2025-02-10T07:03:30.659881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Implement the MLP model.                                                     #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, context_size, d_embed, d_hidden):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.linear1 = nn.Linear(context_size * d_embed, d_hidden, bias=True)\n",
    "        self.linear2 = nn.Linear(d_hidden, vocab_size, bias=True)\n",
    "\n",
    "    def forward(self, x):  # x: (batch_size, context_size)\n",
    "        x_embed = self.embedding(x)  # (batch_size, context_size, d_embed)\n",
    "        x_embed = x_embed.view(x_embed.size(0), -1)  # (batch_size, context_size * d_embed)\n",
    "        x = F.relu(self.linear1(x_embed))  # (batch_size, d_hidden)\n",
    "        x = self.linear2(x)  # (batch_size, vocab_size)\n",
    "        return x\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
   ],
   "id": "f36c4f39c0cfaf5b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:03:30.752825Z",
     "start_time": "2025-02-10T07:03:30.725382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "mlp = MLP(CNNConfig.vocab_size, CNNConfig.context_size, d_embed=CNNConfig.d_embed, d_hidden=CNNConfig.d_hidden)\n",
    "mlp.to(CNNConfig.device)\n",
    "print(mlp)\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in mlp.parameters()))"
   ],
   "id": "c1f99922f7469709",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (embedding): Embedding(27, 16)\n",
      "  (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (linear2): Linear(in_features=64, out_features=27, bias=True)\n",
      ")\n",
      "Number of parameters: 10443\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:03:30.835955Z",
     "start_time": "2025-02-10T07:03:30.798163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "def train(\n",
    "        model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        max_steps: int,\n",
    "        lr: float,\n",
    "        val_interval: int,\n",
    "        log_interval: int,\n",
    "        device: torch.device\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the model for a fixed number of steps.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        train_loader (DataLoader): DataLoader for the training data.\n",
    "        val_loader (DataLoader): DataLoader for the validation data.\n",
    "        max_steps (int): Maximum number of steps to train.\n",
    "        lr (float): Learning rate.\n",
    "        val_interval (int): Interval for validation.\n",
    "        log_interval (int): Interval for logging.\n",
    "        device (torch.device): Device to run the model on.\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    wandb.watch(model, log=\"all\", log_freq=log_interval)\n",
    "    running_loss = 0.0\n",
    "    train_iter = itertools.cycle(train_loader)  # Infinite dataloader\n",
    "    progress_bar = tqdm(total=max_steps, desc=\"Training\", leave=True)\n",
    "\n",
    "    for step in range(1, max_steps + 1):\n",
    "        model.train()\n",
    "        train_inputs, train_targets = next(train_iter)\n",
    "        train_inputs, train_targets = train_inputs.to(device), train_targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(train_inputs)\n",
    "        loss = F.cross_entropy(logits, train_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=f\"{running_loss / step:.4f}\")\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        if step % val_interval == 0:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            total_samples = 0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_targets in val_loader:\n",
    "                    val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                    val_logits = model(val_inputs)\n",
    "                    batch_loss = F.cross_entropy(val_logits, val_targets)\n",
    "                    val_loss += batch_loss.item() * val_inputs.size(0)\n",
    "                    total_samples += val_inputs.size(0)\n",
    "            wandb.log({\"Val Loss\": val_loss / total_samples}, step=step)\n",
    "\n",
    "        if step % log_interval == 0:\n",
    "            wandb.log({\"Train Loss\": running_loss / step}, step=step)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    progress_bar.close()\n",
    "    wandb.finish()"
   ],
   "id": "d39785fb1d5b50bc",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-10T07:03:31.008572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train(\n",
    "    model=mlp,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    max_steps=CNNConfig.max_steps,\n",
    "    lr=CNNConfig.lr,\n",
    "    val_interval=CNNConfig.val_interval,\n",
    "    log_interval=CNNConfig.log_interval,\n",
    "    device=CNNConfig.device\n",
    ")"
   ],
   "id": "47a9e92b0eff104e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 8299/10000 [02:14<00:18, 94.07it/s, loss=2.4206] "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:05:52.050702Z",
     "start_time": "2025-02-10T06:58:36.552473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Write your answer to the questions above.                                    #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "# A1:\n",
    "# A2:\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
   ],
   "id": "ab549d775a5e8c73",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Convolutional Neural Network (CNN)\n",
    "\n",
    "![WaveNet](../../assets/wavenet.png)\n",
    "\n",
    "Instead of connecting each token to all other tokens, CNN uses convolutional layers to connect tokens within a certain range.\n"
   ],
   "id": "ddf42ba9322c757d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T07:05:52.054252Z",
     "start_time": "2025-02-10T06:58:36.593239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Simple WaveNet\n",
    "# Example: WaveNet with 4 convolutional layers\n",
    "# Input: 16 tokens (embedded)\n",
    "# -> Conv -> 8 tokens\n",
    "# -> Conv -> 4 tokens\n",
    "# -> Conv -> 2 tokens\n",
    "# -> Conv -> 1 token: Logits\n",
    "\n",
    "class Conv1d(nn.Module):\n",
    "    def __init__(self,\n",
    "        super().__init__()\n",
    "        # concatenate the two input vectors\n",
    "        self.conv =\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, context_size, d_embed, d_hidden):\n",
    "        super().__init__()\n",
    "        assert context_size & (context_size - 1) == 0, \"Context size should be a power of 2\"\n",
    "        self.n_layers = int(math.log2(context_size))\n",
    "\n",
    "        # Embedding\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            Conv1d(\n",
    "            for _ in range(self.n_layers)\n",
    "        ])\n",
    "\n",
    "        # Output layer\n",
    "        self.linear = nn.Linear(d_hidden, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, context_size, d_embed)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x\n",
    "            x = F.relu(x)\n",
    "\n",
    "        x = x.view(batch_size, -1)  # (batch_size, context_size * d_hidden)\n",
    "        x = self.linear(x)  # (batch_size, vocab_size)\n",
    "        return x"
   ],
   "id": "b123cc3389bfe396",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the model\n",
    "cnn = CNN(CNNConfig.vocab_size, context_size=CNNConfig.context_size, d_embed=CNNConfig.d_embed, d_hidden=CNNConfig.d_hidden)\n",
    "cnn.to(CNNConfig.device)\n",
    "print(cnn)\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in cnn.parameters()))"
   ],
   "id": "32a19396da55c37f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train(\n",
    "    model=cnn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    max_steps=CNNConfig.max_steps,\n",
    "    lr=CNNConfig.lr,\n",
    "    val_interval=CNNConfig.val_interval,\n",
    "    log_interval=CNNConfig.log_interval,\n",
    "    device=CNNConfig.device\n",
    ")"
   ],
   "id": "fafc5675f4a09875"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Rule-based Language Model:\n",
    "    - Params: 26 * (27 + 27^2 + 27^3 + ... + 27^15) = 3 x 10^21\n",
    "- Bigram Language Model:\n",
    "    - Params: 27 * 27 = 729\n",
    "- MLP Language Model:\n",
    "    - Params: 27 * 16 + 16 * 64 + 64 * 27 = 3,456\n",
    "- CNN Language Model:\n",
    "    - Params: 27 * 16 + 16 * 16 + 16 * 16 + 16 * 16 + 16 * 27 = 1,600\n",
    "\n",
    "Neural Network is a compression algorithm. It learns the patterns in the data and stores them in the weights.\n"
   ],
   "id": "5bd59eadf0b7ab66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Information theory\n",
    "[A mathematical theory of communication](https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf)\n",
    "\n",
    "- *The fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point. (Claude Shannon, 1948)*\n",
    "- Received signal = Original signal + Noise\n",
    "    - Goal: **Remove noise**\n",
    "- Entropy: Measure of uncertainty"
   ],
   "id": "88dae6d6f44a3126"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
