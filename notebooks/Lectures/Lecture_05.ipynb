{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lecture 5: Convolutional Neural Networks\n",
    "\n",
    "In this lecture, we will introduce Convolutional Neural Networks (CNN).\n",
    "\n",
    "CNN architecture is widely used in image recognition tasks. However, it can also be used in other domains such as Natural Language Processing and speech recognition. Let's focus on the application in NLP and reproduce WaveNet.\n",
    "\n",
    "CNN papers:\n",
    "- LeNet: [LeCun et al. 1989](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)\n",
    "- AlexNet: [Krizhevsky et al. 2012](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n",
    "- WaveNet: [van den Oord et al. 2016](https://arxiv.org/pdf/1609.03499)"
   ],
   "id": "f598c4dea3f218e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries",
   "id": "7f89f5b0848c0910"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from src.utils import load_text, set_seed, configure_device"
   ],
   "id": "bc3504580e90bbb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "3e47af9eb5496281"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class CNNConfig:\n",
    "    root_dir: str = os.getcwd() + \"/../../\"\n",
    "    dataset_path: str = \"data/names.txt\"\n",
    "    device: torch.device = torch.device('cpu')  # Automatic device configuration\n",
    "\n",
    "    # Tokenizer\n",
    "    vocab_size: int = 0  # Set later\n",
    "\n",
    "    # Model\n",
    "    context_size: int = 5\n",
    "\n",
    "    # Training\n",
    "    val_size: float = 0.1\n",
    "    val_interval: int = 1000\n",
    "    batch_size: int = 32\n",
    "\n",
    "    seed: int = 101"
   ],
   "id": "ecf1ccb60511beaf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reproducibility",
   "id": "502877238c748ea7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "set_seed(CNNConfig.seed)",
   "id": "33f4a4fc4e01baa3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "2d829760e5a2941"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "CNNConfig.device = configure_device()",
   "id": "7adb7527962b2cc4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "ab30418942b02be8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load text and split by lines\n",
    "names = load_text(CNNConfig.root_dir + CNNConfig.dataset_path).splitlines()"
   ],
   "id": "3d8796ce3f291e5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizer",
   "id": "d66e73f17af528d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "chars = [chr(i) for i in range(97, 123)]  # all alphabet characters\n",
    "chars.insert(0, \".\")  # Add special token\n",
    "CNNConfig.vocab_size = len(chars)\n",
    "str2idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx2str = {idx: char for char, idx in str2idx.items()}"
   ],
   "id": "ee51763de0b3a997"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "f105045be1317feb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train-Val Split\n",
    "train_names, val_names = train_test_split(names, test_size=CNNConfig.val_size, random_state=CNNConfig.seed)"
   ],
   "id": "7ab75bfb450734ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Dataset and DataLoader\n",
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, _names, context_size):\n",
    "        self.inputs, self.targets = [], []\n",
    "\n",
    "        for name in _names:\n",
    "            context = [0] * context_size\n",
    "\n",
    "            for char in name + \".\":\n",
    "                idx = str2idx[char]\n",
    "                self.inputs.append(context)\n",
    "                self.targets.append(idx)\n",
    "                context = context[1:] + [idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = torch.tensor(self.inputs[idx])\n",
    "        target_id = torch.tensor(self.targets[idx])\n",
    "        return input_ids, target_id\n",
    "\n",
    "train_dataset = NamesDataset(train_names, context_size=CNNConfig.context_size)\n",
    "val_dataset = NamesDataset(val_names, context_size=CNNConfig.context_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CNNConfig.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CNNConfig.batch_size, shuffle=False)"
   ],
   "id": "8416195bc2d97f4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "fe4a0a60f3f91af4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Multi-Layer Perceptron (MLP)\n",
    "\n",
    "Let's discuss the architecture of a Multi-Layer Perceptron (MLP).\n",
    "\n",
    "![MLP](../../assets/mlp.png)\n",
    "\n",
    "Q1: How do the embedding tokens communicate with each other? What operation is performed to do so?\n",
    "\n",
    "Q2: Let's increase the context size to 16, 64, ... What are the restrictions of increasing the context size?\n",
    "\n"
   ],
   "id": "3c0f1b9715cc66c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Write your answer to the questions above.                                    #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "# A1:\n",
    "# A2:\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
   ],
   "id": "ab549d775a5e8c73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Convolutional Neural Network (CNN)\n",
    "\n",
    "![CNN](../../assets/cnn.png)\n",
    "\n",
    "Instead of connecting each token to all other tokens, CNN uses convolutional layers to connect tokens within a certain range.\n"
   ],
   "id": "ddf42ba9322c757d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b123cc3389bfe396"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
