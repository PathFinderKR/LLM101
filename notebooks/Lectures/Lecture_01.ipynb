{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Lecture 1: Bigram Language Model",
   "id": "32ac1a934eac9271"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing Libraries",
   "id": "bfb95de48ff43fd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T05:03:47.034970Z",
     "start_time": "2025-02-04T05:03:47.032026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "from src.utils import load_text, set_seed, configure_device\n",
    "from src.tokenizer import CharTokenizer\n",
    "from src.train import split_text, TextDataset, setup_optimizer, setup_scheduler, train_epoch, evaluate"
   ],
   "id": "8c5c4b762db5214b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "e8ddd620c0f940a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T05:03:38.964820Z",
     "start_time": "2025-02-04T05:03:38.961614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class BigramConfig:\n",
    "    root_dir: str = os.getcwd() + \"/../../\"\n",
    "    dataset_path: str = \"data/raw/names.txt\"\n",
    "    device: torch.device = torch.device('cpu')  # Automatic device configuration\n",
    "\n",
    "    # Tokenizer\n",
    "    tokenizer: str = \"char\"\n",
    "    vocab_size: int = 256\n",
    "\n",
    "    seed: int = 101"
   ],
   "id": "791f0b593bc9703d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reproducibility",
   "id": "21fb291e55dc5139"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "set_seed(BigramConfig.seed)",
   "id": "4dc1f2ec01ac0512"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "8dfd4c1f363fff82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "BigramConfig.device = configure_device()",
   "id": "1204ec413ac9e583"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizer",
   "id": "6f582f4182c980f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = CharTokenizer()\n",
    "\n"
   ],
   "id": "15fbebb70f3bb327"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "fbff5bc80dc11f7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Bigram(nn.Module):\n",
    "    def __init__(self, config: BigramConfig):\n",
    "        super(Bigram, self).__init__()\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.probs = nn.Parameter(torch.randn(config.vocab_size, config.vocab_size))\n",
    "\n",
    "    def forward(self, x):  # x: (batch_size, 1)\n",
    "        logits = self.probs[x]  # (batch_size, 1, vocab_size)\n",
    "        return logits\n",
    "\n",
    "    def loss(self, logits, target):\n",
    "        logits = logits.view(-1, self.vocab_size)  # (batch_size, vocab_size)\n",
    "        target = target.view(-1)  # (batch_size)\n",
    "        return F.cross_entropy(logits, target)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, tokenizer, prompt, max_new_tokens, device, temperature=1.0):\n",
    "        if temperature < 0.0 or temperature > 1.0:\n",
    "            raise ValueError(\"temperature must be between 0.0 and 1.0\")\n",
    "\n",
    "        self.eval()\n",
    "        print(prompt)\n",
    "\n",
    "        # Encode\n",
    "        x = tokenizer.encode(prompt).to(device).unsqueeze(0)  # (batch_size=1, prompt_size)\n",
    "\n",
    "        # Generation loop\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Truncate\n",
    "            context = x[:, -1:]  # (batch_size=1, 1)\n",
    "\n",
    "            # Forward\n",
    "            logits = self.forward(context)[:, -1, :] / temperature  # (batch_size=1, vocab_size)\n",
    "\n",
    "            # Sample\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)  # (batch_size=1, 1)\n",
    "\n",
    "            # Concatenate\n",
    "            x = torch.cat([x, next_token], dim=-1)  # (batch_size=1, 2)\n",
    "\n",
    "            # Decode\n",
    "            text = tokenizer.decode([next_token[0].item()])\n",
    "            print(text, end='', flush=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model = Bigram(BigramConfig()).to(BigramConfig.device)",
   "id": "feceb91412b78d4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "1dc38001a651e918"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T05:03:40.439671Z",
     "start_time": "2025-02-04T05:03:40.436314Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text data from /Users/pathfinder/Documents/GitHub/LLM101/notebooks/Lectures/../../data/raw/names.txt (length: 228145 characters).\n"
     ]
    }
   ],
   "execution_count": 10,
   "source": "names_text = load_text(BigramConfig.root_dir + BigramConfig.dataset_path)",
   "id": "64aa03512bdd628c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "f43fa4443ede82a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "88f70895c35dcdaf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generation",
   "id": "33ca574ebffc4aa9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4c1657b3dc5aa842"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
