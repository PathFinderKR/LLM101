{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Assignment 4",
   "id": "1d8158dfddb2ac72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing Libraries",
   "id": "4e20e9597869b589"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from src.utils import load_text, set_seed, configure_device\n",
    "%matplotlib inline"
   ],
   "id": "8ae97a80f931ff9a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "37475b8f118bf62f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class MLPConfig:\n",
    "    root_dir: str = os.getcwd() + \"/../../\"\n",
    "    dataset_path: str = \"data/names.txt\"\n",
    "    device: torch.device = torch.device('cpu')  # Automatic device configuration\n",
    "\n",
    "    # Tokenizer\n",
    "    vocab_size: int = 0  # Set later\n",
    "    \n",
    "    # Model\n",
    "    context_size: int = 3\n",
    "    d_embed: int = 16\n",
    "    d_hidden: int = 64\n",
    "    \n",
    "    # Training\n",
    "    val_size: float = 0.1\n",
    "    val_interval: int = 1000\n",
    "    batch_size: int = 32\n",
    "    lr: float = 2e-3\n",
    "    max_steps: int = 10000\n",
    "\n",
    "    seed: int = 101"
   ],
   "id": "ab74c7e96ee2918c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reproducibility",
   "id": "b37b1da5eb884f97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "set_seed(MLPConfig.seed)",
   "id": "5aac9ba3a2c94cdd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "8046aa4cb3a6469f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "MLPConfig.device = configure_device()",
   "id": "ec9748db8884490e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizer",
   "id": "db4d6ad274a6fbbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "chars = [chr(i) for i in range(97, 123)]  # all alphabet characters\n",
    "chars.insert(0, \".\")  # Add special token\n",
    "MLPConfig.vocab_size = len(chars)\n",
    "str2idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx2str = {idx: char for char, idx in str2idx.items()}"
   ],
   "id": "e9dbce085edefdc4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "576b370aea4c1555"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "names = load_text(MLPConfig.root_dir + MLPConfig.dataset_path).splitlines()",
   "id": "8cc4922d3b541a53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "31bf63ac06c3b24c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train-Val Split\n",
    "train_names, val_names = train_test_split(names, test_size=MLPConfig.val_size, random_state=MLPConfig.seed)"
   ],
   "id": "f91738376b5a8431"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def prepare_dataset(_names):\n",
    "    _inputs, _targets = [], []\n",
    "\n",
    "    for name in _names:\n",
    "        _context = [0] * MLPConfig.context_size\n",
    "\n",
    "        for char in name + \".\":\n",
    "            idx = str2idx[char]\n",
    "            _inputs.append(_context)\n",
    "            _targets.append(idx)\n",
    "            _context = _context[1:] + [idx]  # Shift the context by 1 character\n",
    "\n",
    "    _inputs = torch.tensor(_inputs)\n",
    "    _targets = torch.tensor(_targets)\n",
    "\n",
    "    return _inputs, _targets"
   ],
   "id": "44931589173ddd84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 1: PyTorch DataLoader\n",
    "\n",
    "We have been using plain Python lists to and then converted them to PyTorch tensors. This is not efficient since it is loading the entire dataset into memory.\n",
    "\n",
    "PyTorch provides `Dataset` and `DataLoader` class to load the data in memory on the fly. [PyTorch Documentation](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "\n",
    "Refactor the `prepare_dataset` function into a PyTorch `Dataset` class and use the `DataLoader` to efficiently load the data in batches."
   ],
   "id": "27772dc3e0015a64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Dataset\n",
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, _names, context_size):\n",
    "        self.names = _names\n",
    "        self.context_size = context_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name = self.names[idx]\n",
    "        return name"
   ],
   "id": "b550956d3a003a7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the dataset\n",
    "train_dataset = NamesDataset(train_names, MLPConfig.context_size)\n",
    "val_dataset = NamesDataset(val_names, MLPConfig.context_size)"
   ],
   "id": "352be875ddc0fa7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=MLPConfig.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=MLPConfig.batch_size, shuffle=False)"
   ],
   "id": "a9e04718940ac55d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "77b0001776a8667d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 2: MLP Model\n",
    "\n",
    "Initialize the weights of the model using the `Kaiming` initialization."
   ],
   "id": "5bec79a9421554b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MLP(nn.Module):\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Define the __init__ and forward methods for the MLP model.                   #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    def __init__(self, vocab_size, context_size, d_embed, d_hidden):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.linear1 = nn.Linear(context_size * d_embed, d_hidden, bias=True)\n",
    "        self.linear2 = nn.Linear(d_hidden, vocab_size, bias=True)\n",
    "        \n",
    "    def forward(self, x):  # x: (batch_size, context_size)\n",
    "        x_embed = self.embedding(x)  # (batch_size, context_size, d_embed)\n",
    "        x_embed = x_embed.view(x_embed.size(0), -1)  # (batch_size, context_size * d_embed)\n",
    "        x = F.relu(self.linear1(x_embed))  # (batch_size, d_hidden)\n",
    "        x = self.linear2(x)  # (batch_size, vocab_size)\n",
    "        return x\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
   ],
   "id": "e5ce5b250ec839a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the model\n",
    "mlp = MLP(MLPConfig.vocab_size, MLPConfig.context_size, MLPConfig.d_embed, MLPConfig.d_hidden)\n",
    "mlp.to(MLPConfig.device) # Move the model to the device\n",
    "print(mlp)\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in mlp.parameters()))"
   ],
   "id": "e70046f646dc9e37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "62d6bd917a11788c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(model, max_steps=MLPConfig.max_steps):\n",
    "    steps = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=MLPConfig.lr)\n",
    "    \n",
    "    for step in range(1, max_steps + 1):\n",
    "        # Training\n",
    "        # Sample batch\n",
    "        idx = torch.randperm(len(train_inputs))[:MLPConfig.batch_size]\n",
    "        x, y = train_inputs[idx], train_targets[idx]\n",
    "        x, y = x.to(MLPConfig.device), y.to(MLPConfig.device)  # Move the data to the device\n",
    "        \n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Implement the forward pass and the backward pass                             #\n",
    "        ################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        # print(logits[0])\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        \n",
    "        # Validation\n",
    "        if step % MLPConfig.val_interval == 0:\n",
    "            # Validation loss\n",
    "            with torch.no_grad():\n",
    "                val_logits = model(val_inputs.to(MLPConfig.device))\n",
    "                val_loss = F.cross_entropy(val_logits, val_targets.to(MLPConfig.device)).item()\n",
    "                val_losses.append(val_loss)\n",
    "            \n",
    "        # Logging\n",
    "        steps.append(step)\n",
    "        train_losses.append(loss.item())\n",
    "        if step == 1:\n",
    "            print(f\"Initial Train Loss = {loss.item():.4f}\")\n",
    "        if step % MLPConfig.val_interval == 0:\n",
    "            print(f\"Step {step}: Train Loss = {loss.item():.4f}, Val Loss = {val_loss:.4f}\")\n",
    "    \n",
    "    final_val_logits = model(val_inputs.to(MLPConfig.device))\n",
    "    final_val_loss = F.cross_entropy(final_val_logits, val_targets.to(MLPConfig.device)).item()\n",
    "    print(f\"Final Validation Loss = {final_val_loss:.4f}\")\n",
    "\n",
    "    # Plot the loss\n",
    "    if max_steps > MLPConfig.val_interval:\n",
    "        plt.figure()\n",
    "        plt.plot(steps, train_losses, label=\"Train\")\n",
    "        plt.plot(steps[::MLPConfig.val_interval], val_losses, label=\"Validation\")\n",
    "        plt.xlabel(\"Steps\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ],
   "id": "b7a382984c75ee64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train(model=mlp, max_steps=MLPConfig.max_steps)",
   "id": "16545fba72cbaa95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "af0c069cfb0e2b6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5f7e1f183f701114"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "fc1bc1aa80469ebe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7a5b94249516fce6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
