{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Assignment 2",
   "id": "1d8158dfddb2ac72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 1: Train Bigram Language Model (Neural Network Approach)\n",
    "\n",
    "Let's continue with the Bigram Language Model from the lecture and finish the training loop."
   ],
   "id": "3b18f121d3812f4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Importing Libraries",
   "id": "c011cbf15834af26"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:38.483142Z",
     "start_time": "2025-02-09T09:57:37.518442Z"
    }
   },
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "from src.utils import load_text, set_seed"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Configuration",
   "id": "4a4a0b5274f4dca2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:38.489573Z",
     "start_time": "2025-02-09T09:57:38.484658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class BigramConfig:\n",
    "    root_dir: str = os.getcwd() + \"/../../\"\n",
    "    dataset_path: str = \"data/names.txt\"\n",
    "\n",
    "    # Tokenizer\n",
    "    vocab_size: int = 0  # Set later\n",
    "\n",
    "    seed: int = 101"
   ],
   "id": "ef1253f6800c36c1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Reproducibility",
   "id": "5726a09b7e375389"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:38.511369Z",
     "start_time": "2025-02-09T09:57:38.491293Z"
    }
   },
   "cell_type": "code",
   "source": "set_seed(BigramConfig.seed)",
   "id": "5e4d38445588cdbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 101\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset",
   "id": "d74be7e01434a14b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:38.520550Z",
     "start_time": "2025-02-09T09:57:38.512761Z"
    }
   },
   "cell_type": "code",
   "source": "names = load_text(BigramConfig.root_dir + BigramConfig.dataset_path).splitlines()",
   "id": "32e86ea6f15f11b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text data from /mnt/c/Users/cheir/GitHub/LLM101/notebooks/Assignments/../../data/names.txt (length: 228145 characters).\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preprocessing",
   "id": "3aff6f7e1bbade4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:38.526668Z",
     "start_time": "2025-02-09T09:57:38.521736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add special token\n",
    "names = [\".\" + name + \".\" for name in names]"
   ],
   "id": "ed24c0db0ce9da98",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tokenizer",
   "id": "f9e38655c11342dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:38.538602Z",
     "start_time": "2025-02-09T09:57:38.527809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chars = [chr(i) for i in range(97, 123)]  # all alphabet characters\n",
    "chars.insert(0, \".\")  # Add special token\n",
    "BigramConfig.vocab_size = len(chars)\n",
    "str2idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx2str = {idx: char for char, idx in str2idx.items()}"
   ],
   "id": "9a2f768e619dfb02",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model",
   "id": "91e4e1dda633584d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:38.546933Z",
     "start_time": "2025-02-09T09:57:38.539782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize weights\n",
    "W = torch.randn(BigramConfig.vocab_size, BigramConfig.vocab_size, requires_grad=True)\n",
    "b = torch.randn(BigramConfig.vocab_size, requires_grad=True)\n",
    "params = [W, b]"
   ],
   "id": "523dd8edb6b3e9c8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "51ca7979aafb68a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:38.612451Z",
     "start_time": "2025-02-09T09:57:38.548044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set of Input, Target pairs\n",
    "inputs, targets = [], []\n",
    "for name in names:\n",
    "    for char1, char2 in zip(name, name[1:]):\n",
    "        input = str2idx[char1]\n",
    "        target = str2idx[char2]\n",
    "        inputs.append(input)\n",
    "        targets.append(target)\n",
    "\n",
    "# Convert to tensor\n",
    "inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "targets = torch.tensor(targets, dtype=torch.long)"
   ],
   "id": "f8f5165e72e37f1b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:38.617557Z",
     "start_time": "2025-02-09T09:57:38.613826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Number of Input, Target pairs: {len(inputs)}\")\n",
    "print(f\"Input shape: {inputs.shape}\")\n",
    "print(f\"Target shape: {targets.shape}\")\n",
    "print(f\"First (Input, Target): ({inputs[0]}, {targets[0]})\")\n",
    "print(f\"Second (Input, Target): ({inputs[1]}, {targets[1]})\")"
   ],
   "id": "ebe57ba03f098d90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Input, Target pairs: 228146\n",
      "Input shape: torch.Size([228146])\n",
      "Target shape: torch.Size([228146])\n",
      "First (Input, Target): (0, 5)\n",
      "Second (Input, Target): (5, 13)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:38.636955Z",
     "start_time": "2025-02-09T09:57:38.619320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# One-hot encoding\n",
    "# ------------------\n",
    "# Write your implementation here.\n",
    "inputs_encoded = F.one_hot(inputs, num_classes=BigramConfig.vocab_size)\n",
    "# ------------------\n",
    "\n",
    "# Convert data type to float\n",
    "inputs_encoded = inputs_encoded.float()"
   ],
   "id": "4baab50fd5515e6a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:45.301216Z",
     "start_time": "2025-02-09T09:57:38.638684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training Loop\n",
    "steps = 100\n",
    "lr = 10\n",
    "\n",
    "for step in range(steps):\n",
    "    # ------------------\n",
    "    # Write your implementation here.\n",
    "    # Forward pass\n",
    "    logits = inputs_encoded @ W + b\n",
    "    probs = logits.exp() / logits.exp().sum(dim=-1, keepdim=True)\n",
    "    # ------------------\n",
    "    \n",
    "    # loss\n",
    "    log_probs = torch.log(probs + 1e-9)  # Add small value to prevent log(0)\n",
    "    loss = -log_probs[torch.arange(len(targets)), targets].mean()\n",
    "\n",
    "    # ------------------\n",
    "    # Write your implementation here.\n",
    "    # Backward pass\n",
    "    for param in params:\n",
    "        param.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update weights\n",
    "    for param in params:\n",
    "        param.data = param.data - lr * param.grad\n",
    "    # ------------------\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(f\"Step {step}, Loss {loss.item():.4f}\")"
   ],
   "id": "1a5ef07b0b820e5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss 4.3936\n",
      "Step 10, Loss 2.8529\n",
      "Step 20, Loss 2.7058\n",
      "Step 30, Loss 2.6360\n",
      "Step 40, Loss 2.5956\n",
      "Step 50, Loss 2.5697\n",
      "Step 60, Loss 2.5517\n",
      "Step 70, Loss 2.5385\n",
      "Step 80, Loss 2.5286\n",
      "Step 90, Loss 2.5207\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Inference",
   "id": "4d956fef0a027963"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:45.309202Z",
     "start_time": "2025-02-09T09:57:45.302494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a function to generate a name\n",
    "def generate_name():\n",
    "    new_name = []\n",
    "    start_idx = str2idx[\".\"]\n",
    "    \n",
    "    while True:\n",
    "        # ------------------\n",
    "        # Write your implementation here.\n",
    "        # Forward pass\n",
    "        x_encoded = F.one_hot(torch.tensor([start_idx]), num_classes=BigramConfig.vocab_size).float()\n",
    "        logits = torch.matmul(x_encoded, W) + b\n",
    "        prob = logits.exp() / logits.exp().sum(dim=-1, keepdim=True)\n",
    "        \n",
    "        # Sample\n",
    "        next_idx = torch.multinomial(prob, num_samples=1).item()\n",
    "        \n",
    "        # Decode\n",
    "        new_char = idx2str[next_idx]\n",
    "        new_name.append(new_char)\n",
    "        \n",
    "        # Update\n",
    "        start_idx = next_idx\n",
    "        \n",
    "        # Break if \".\"\n",
    "        if next_idx == str2idx[\".\"]:\n",
    "            break\n",
    "        # ------------------\n",
    "    return ''.join(new_name)\n",
    "\n",
    "# Generate 5 names\n",
    "for _ in range(5):\n",
    "    print(generate_name())"
   ],
   "id": "b31dfacd08b51cd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aymienzeta.\n",
      "dhchatt.\n",
      "rneara.\n",
      "gn.\n",
      "todeleanion.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Extra Credit\n",
    "\n",
    "We have already made our own custom auto-grad Tensor class. Let's use it!\n",
    "\n",
    "Train the Bigram Language Model using our custom auto-grad Tensor class.\n",
    "\n",
    "**Do not use any built-in PyTorch functions.** (other deep learning libraries are also prohibited)"
   ],
   "id": "11d00faaddbe4b44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:45.316125Z",
     "start_time": "2025-02-09T09:57:45.310273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tensor:\n",
    "    def __init__(self, data, _children=(), _operation=''):\n",
    "        self.data = data\n",
    "        self._prev = set(_children)\n",
    "        self.gradient = 0\n",
    "        self._backward = lambda: None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"tensor=({self.data})\"\n",
    "\n",
    "    def __add__(self, other):  # self + other\n",
    "        output = Tensor(self.data + other.data, (self, other), '+')\n",
    "        def _backward():\n",
    "            self.gradient = 1 * output.gradient\n",
    "            other.gradient = 1 * output.gradient\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "\n",
    "    def __mul__(self, other):  # self * other\n",
    "        output = Tensor(self.data * other.data, (self, other), '*')\n",
    "        def _backward():\n",
    "            self.gradient = other.data * output.gradient\n",
    "            other.gradient = self.data * output.gradient\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "\n",
    "    def tanh(self):  # tanh(self)\n",
    "        output = Tensor(math.tanh(self.data), (self,), 'tanh')\n",
    "        def _backward():\n",
    "            self.gradient = (1.0 - math.tanh(self.data) ** 2) * output.gradient\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "\n",
    "    def __pow__(self, power):  # self ** power\n",
    "        assert isinstance(power, (int, float)), \"Power must be an int or a float\"\n",
    "        output = Tensor(self.data ** power, (self,), f'**{power}')\n",
    "        def _backward():\n",
    "            self.gradient = power * (self.data ** (power - 1)) * output.gradient\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "        self.gradient = 1\n",
    "        for node in reversed(topo):\n",
    "            node._backward()\n",
    "\n",
    "    def __neg__(self): # -self\n",
    "        return self * Tensor(-1.0)\n",
    "\n",
    "    def __sub__(self, other): # self - other\n",
    "        return self + (-other)"
   ],
   "id": "e6f26efc1212bb48",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T09:57:45.325899Z",
     "start_time": "2025-02-09T09:57:45.317066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------\n",
    "# Write your implementation here.\n",
    "\n",
    "# ------------------"
   ],
   "id": "e3b7815ada66df8c",
   "outputs": [],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
